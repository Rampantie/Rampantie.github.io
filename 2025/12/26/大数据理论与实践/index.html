

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.jpg">
  <link rel="icon" href="/img/avatar.jpg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jeremy Cheng">
  <meta name="keywords" content="">
  
    <meta name="description" content="大数据理论与实践 Ⅰ 2025 年秋季 - 复习提纲 CHAPTER 01 大数据综述与发展脉络 核心掌握：大数据 4V 特性、Google 三大论文及生态基础 一、大数据 4V 特性深度解析 V1 Volume・数据规模  定义：数据规模巨大，从 GB 到 PB 甚至 EB 级，单机存储与计算不可行。 系统约束：必须采用水平扩展架构，优先考虑容错设计。典型组件如 HDFS 提供分布式存储。  V">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据理论与实践">
<meta property="og:url" content="http://example.com/2025/12/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="自渡 × 稊园">
<meta property="og:description" content="大数据理论与实践 Ⅰ 2025 年秋季 - 复习提纲 CHAPTER 01 大数据综述与发展脉络 核心掌握：大数据 4V 特性、Google 三大论文及生态基础 一、大数据 4V 特性深度解析 V1 Volume・数据规模  定义：数据规模巨大，从 GB 到 PB 甚至 EB 级，单机存储与计算不可行。 系统约束：必须采用水平扩展架构，优先考虑容错设计。典型组件如 HDFS 提供分布式存储。  V">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-12-26T09:32:51.000Z">
<meta property="article:modified_time" content="2025-12-26T12:34:54.600Z">
<meta property="article:author" content="Jeremy Cheng">
<meta property="article:tag" content="Big Data">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>大数据理论与实践 - 自渡 × 稊园</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"VuFNqHSWzChINkJFPCBgzzAA-gzGzoHsz","app_key":"CiPa7Le2LyTY1FdufKsHqM1z","server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 8.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>JeremyIrving的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="大数据理论与实践"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-12-26 17:32" pubdate>
          2025年12月26日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          60 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">大数据理论与实践</h1>
            
            
              <div class="markdown-body">
                
                <h1>大数据理论与实践 Ⅰ 2025 年秋季 - 复习提纲</h1>
<h2 id="CHAPTER-01-大数据综述与发展脉络">CHAPTER 01 大数据综述与发展脉络</h2>
<h3 id="核心掌握：大数据-4V-特性、Google-三大论文及生态基础">核心掌握：大数据 4V 特性、Google 三大论文及生态基础</h3>
<h3 id="一、大数据-4V-特性深度解析">一、大数据 4V 特性深度解析</h3>
<h4 id="V1-Volume・数据规模">V1 Volume・数据规模</h4>
<ul>
<li>定义：数据规模巨大，从 GB 到 PB 甚至 EB 级，单机存储与计算不可行。</li>
<li>系统约束：必须采用<strong>水平扩展</strong>架构，优先考虑<strong>容错</strong>设计。典型组件如 HDFS 提供分布式存储。</li>
</ul>
<h4 id="V2-Variety・数据类型">V2 Variety・数据类型</h4>
<ul>
<li>定义：数据类型多样，结构化 (数据库表)、半结构化 ( XML/JSON )、非结构化 (日志 / 图片 / 视频) 并存。</li>
<li>系统约束：需要<strong>多格式接入</strong>与<strong>统一处理抽象</strong> , 如 Hive 支持多种存储格式。</li>
</ul>
<h4 id="V3-Velocity・处理速度">V3 Velocity・处理速度</h4>
<ul>
<li>定义：数据生成与处理速度快，要求实时或准实时响应。</li>
<li>系统约束：系统需具备<strong>高吞吐</strong>与<strong>低延迟</strong>能力，强调<strong>流批协同</strong> , 如 Spark/Flink 分别处理批 / 流场景。</li>
</ul>
<h4 id="V4-Value・价值密度">V4 Value・价值密度</h4>
<ul>
<li>定义：价值密度低，海量数据中只有少量有价值信息，价值获取依赖 “提纯” 过程。</li>
<li>系统约束：倒逼系统强调<strong>批处理 + 统计建模</strong> , 通过特征工程、机器学习等手段提取价值。</li>
</ul>
<blockquote>
<p>✅ 答题框架: 4V → 系统需求 → 典型组件4V 给出定义后，补充 “带来的系统约束”，例如 Volume 对应分布式扩展、 Velocity 对应吞吐与延迟权衡。将约束落到生态视角：存储系统 (HDFS) + 计算框架 ( MapReduce/Spark ) + 协调服务 ( ZooKeeper ) 构成工程闭环。</p>
</blockquote>
<h3 id="二、Google-三大奠基论文与生态闭环">二、Google 三大奠基论文与生态闭环</h3>
<h4 id="GFS-Google-File-System">GFS - Google File System</h4>
<ul>
<li>定位：面向海量数据的分布式存储系统</li>
<li>设计目标：大文件存储、顺序读写优化、容错优先</li>
<li>开源实现: HDFS (Hadoop Distributed File System)</li>
<li>核心思想: Block 存储 + 多副本 + Master / Slave 架构</li>
</ul>
<h4 id="MR-MapReduce">MR - MapReduce</h4>
<ul>
<li>定位：面向海量数据的离线批处理计算模型</li>
<li>编程抽象: Map (映射)+ Reduce (归并) 两个阶段</li>
<li>核心能力：自动并行化、容错、任务调度</li>
<li>设计哲学：移动计算比移动数据更经济</li>
</ul>
<h4 id="BT-Bigtable">BT - Bigtable</h4>
<ul>
<li>定位：面向大规模结构化数据的在线服务存储</li>
<li>数据模型：列族存储模型，支持稀疏数据</li>
<li>设计特点：高吞吐、可扩展、容错</li>
<li>开源实现: HBase、Cassandra</li>
</ul>
<h3 id="三、存储-计算-服务的分工与协作">三、存储 / 计算 / 服务的分工与协作</h3>
<ol>
<li>存储层：GFS / HDFS 负责数据持久化，提供高容错、高吞吐的分布式存储能力，支持大文件顺序读写。</li>
<li>计算层：MapReduce / Spark 负责数据处理，提供分布式计算框架，支持批处理、流处理等多种计算模式。</li>
<li>服务层：Bigtable / HBase 负责在线服务，提供低延迟、高并发的随机读写能力，支持海量结构化数据访问。</li>
</ol>
<h3 id="四、高频考点与易错点辨析">四、高频考点与易错点辨析</h3>
<ol>
<li>论文级概念 vs 开源实现：论文描述设计思想与系统模型，开源实现 (如 HDFS/Spark) 是具体的工程实现。题干出现具体开源组件名时，通常不是论文原名。</li>
<li>高频表达：吞吐优先与顺序 I/O —— 大数据底座系统常优先优化顺序读写吞吐与故障容忍，而不是单次随机访问的低延迟，这是与 OLTP 系统的本质区别。</li>
<li>典型易错题
<ul>
<li>❌ 错误选项: “HDFS 是 Google 三大论文之一” | ✅ 正确答案: GFS/MapReduce/Bigtable</li>
<li>❌ 错误理解: “大数据系统优先优化随机访问低延迟” | ✅ 正确理解：优先优化顺序读写吞吐与容错</li>
<li>❌ 错误表述: “Value 密度高所以适合实时处理” | ✅ 正确表述: Value 密度低需批处理 + 统计建模提纯</li>
</ul>
</li>
</ol>
<hr>
<h2 id="CHAPTER-02-分布式协调与一致性基础">CHAPTER 02 分布式协调与一致性基础</h2>
<h3 id="核心掌握：ZooKeeper-定位、数据模型、集群架构与-Watch-机制">核心掌握：ZooKeeper 定位、数据模型、集群架构与 Watch 机制</h3>
<h3 id="一、ZooKeeper-核心定位与数据模型">一、ZooKeeper 核心定位与数据模型</h3>
<h4 id="核心定位">核心定位</h4>
<ul>
<li>核心定位: <strong>分布式协调服务</strong>，解决分布式系统中的协调问题</li>
<li>解决的问题：提供少量关键元数据的一致性存储与变更通知（选主 / 成员管理 / 配置分发 / 分布式锁）</li>
<li>不擅长：存储大量业务数据或高吞吐写入 (设计目标不是数据仓库或消息系统)</li>
</ul>
<h4 id="数据模型：ZNode-目录树">数据模型：ZNode 目录树</h4>
<ul>
<li>ZNode : 类文件系统的层级节点，可存放少量数据与 ACL ，维护版本号等元信息
<ul>
<li>持久节点：显式删除前一直存在，适合配置、服务目录</li>
<li>临时节点：与 Session 绑定， Session 失效后自动删除</li>
<li>顺序节点：创建时自动追加单调递增序号</li>
</ul>
</li>
<li>Session 与临时节点的故障语义：Session 是客户端与 ZooKeeper 集群的逻辑连接，临时节点绑定 Session 可实现故障自动感知，支撑选主、存活探测等能力。</li>
</ul>
<h4 id="Watch-机制：变更通知的基础">Watch 机制：变更通知的基础</h4>
<ul>
<li>Watch : <strong>一次性触发</strong>的监听，触发后若需持续观察必须重新注册</li>
<li>工程含义：客户端需要处理边界情况（事件丢失、事件重放、重复触发、重新注册）</li>
</ul>
<h3 id="二、集群角色与多数派机制">二、集群角色与多数派机制</h3>
<h4 id="集群角色：Leader-Follower-Observer">集群角色：Leader/Follower/Observer</h4>
<ol>
<li><strong>Leader・领导者</strong>：负责事务请求的提案与提交，是集群中唯一处理写请求的角色</li>
<li><strong>Follower・跟随者</strong>：参与多数派确认，对客户端提供读服务，可成为 Leader 候选者</li>
<li><strong>Observer・观察者</strong>：不参与投票，用于扩展读吞吐，跨区域部署时降低网络延迟</li>
</ol>
<h4 id="写入与读取路径">写入与读取路径</h4>
<ul>
<li>写入路径：客户端写请求→Leader→生成提案→Follower 投票→多数派确认→提交生效</li>
<li>读取路径：客户端读请求→任意节点 (Leader / Follower / Observer)→返回本地数据</li>
<li>工程直觉：写入要<strong>过多数派</strong>，读取尽量就近，但读到的状态是否 “最新” 取决于同步语义</li>
</ul>
<h4 id="多数派-Quorum-基本原则">多数派 (Quorum) 基本原则</h4>
<ol>
<li>核心目的：写入与选主依赖多数派仲裁以避免脑裂 (Split-Brain)，任何两个多数派集合必然有交集，从而保障一致性推进。</li>
<li>容错能力公式：<strong>2n + 1</strong> → 容忍 n 台故障需要 2n+1 台节点（3 台容 1、5 台容 2、7 台容 3）</li>
<li>集群规模取奇数原因：奇数节点的容错能力优于偶数，偶数节点资源利用率低。</li>
</ol>
<h3 id="三、生态依赖与典型应用场景">三、生态依赖与典型应用场景</h3>
<ul>
<li>HDFS HA：ZooKeeper + ZKFC 完成 Active/Standby 的健康检查、选主与自动切换</li>
<li>HBase 依赖：ZooKeeper 做 Master / RegionServer 协调，管理 Master 选举、RS 存活监控、元数据定位</li>
<li>Kafka 历史依赖：依赖 ZK 做控制器选举、元数据管理，新版逐步移除 ZK 依赖，转向 KRaft 模式</li>
</ul>
<blockquote>
<p>✅ 答题框架：定位 → 核心抽象 → 典型能力 → 生态依赖定位：分布式协调服务 (不是存储 / 计算引擎)核心抽象：Session + ZNode + Watch典型能力：选主、配置管理、命名服务、分布式锁、成员管理生态依赖：HDFS HA、HBase、Kafka 历史依赖</p>
</blockquote>
<hr>
<h2 id="CHAPTER-03-HDFS-基础机制与读写路径">CHAPTER 03 HDFS 基础机制与读写路径</h2>
<h3 id="核心掌握：HDFS-架构组件、-Block-机制、元数据管理与读写流程">核心掌握：HDFS 架构组件、 Block 机制、元数据管理与读写流程</h3>
<h3 id="一、HDFS-架构与-Block-存储机制">一、HDFS 架构与 Block 存储机制</h3>
<h4 id="核心组件">核心组件</h4>
<ol>
<li><strong>NN - NameNode</strong>：Master 管理节点，管理命名空间、元数据、权限，协调副本策略与集群状态；不在数据读写路径上传输实际数据。</li>
<li><strong>DN - DataNode</strong>：Slave 工作节点，存储实际数据块 (Block) 与校验和，执行客户端读写请求；周期性向 NameNode 发送心跳与块报告。</li>
<li><strong>Client</strong>：与 NameNode 交互获取元数据，与 DataNode 交互传输数据；先问 NN 拿地址 (控制流)，再找 DN 传数据 (数据流)。</li>
</ol>
<h4 id="Block-与副本机制">Block 与副本机制</h4>
<ul>
<li>Block 概念：文件被切分为固定大小的 Block (默认 128 MiB)，最后一个 Block 可小于默认值。</li>
<li>副本策略：默认 3 副本，机架感知策略：本地→同机架→跨机架，平衡容错与带宽。</li>
<li>存储适用性：<strong>适合高吞吐量的顺序读写、大文件存储</strong>；<strong>不适合海量小文件</strong>（NN 内存瓶颈、寻址开销大、存储浪费）。</li>
</ul>
<h3 id="二、元数据持久化与安全模式">二、元数据持久化与安全模式</h3>
<h4 id="FSImage-静态快照">FSImage : 静态快照</h4>
<ul>
<li>定义：文件系统元数据的静态快照，包含目录树、权限、文件属性等</li>
<li>存储内容：文件到 Block 的映射关系、文件权限、 ACL 、修改时间等</li>
<li>关键: <strong>Block 的位置信息不持久化到 FSImage</strong></li>
</ul>
<h4 id="EditLog-增量日志">EditLog : 增量日志</h4>
<ul>
<li>定义：记录所有元数据变更操作的增量日志，如创建文件、删除文件、修改权限</li>
<li>作用：保证元数据变更的持久性，支持故障恢复</li>
<li>恢复机制: NameNode 启动时加载 FSImage ，重放 EditLog 恢复到最新状态</li>
</ul>
<h4 id="Block-位置信息的特殊处理">Block 位置信息的特殊处理</h4>
<ul>
<li>关键设计: Block 的位置信息 不持久化到 FSImage，原因是位置动态变化，持久化会导致 EditLog 急剧膨胀。</li>
<li>维护方式: DataNode 启动时上报并动态维护在 NameNode 内存中，通过 Block Report 定期上报 (默认 6 小时)。</li>
</ul>
<h4 id="安全模式-Safe-Mode">安全模式 (Safe Mode)</h4>
<ul>
<li>定义: NameNode 启动时的保护状态，<strong>只读不写</strong></li>
<li>目的：等待 DataNode 上报 Block 信息，直到满足 “最小副本率” 等阈值后自动退出</li>
<li>触发条件: NN 启动时 Block 上报率低、DN 存活数过少、NN 磁盘空间不足</li>
</ul>
<h3 id="三、HDFS-读写流程与性能优化">三、HDFS 读写流程与性能优化</h3>
<h4 id="读流程-Client-→-NameNode-→-DataNode">读流程: Client → NameNode → DataNode</h4>
<ol>
<li>Client 请求 NameNode，指定文件路径</li>
<li>NameNode 返回 Block 位置（按距离排序）</li>
<li>Client 直连 DataNode 读取数据</li>
<li>故障切换与校验：DN 故障自动切换副本，读取完成校验完整性</li>
</ol>
<h4 id="写流程-Client-→-NameNode-→-Pipeline">写流程: Client → NameNode → Pipeline</h4>
<ol>
<li>Client 请求 NameNode 创建文件，NN 检查权限与文件是否存在</li>
<li>建立 Pipeline 客户端与 DN 建立数据流管道，数据按 Packet 写入</li>
<li>Pipeline 写入与复制：Client→DN1→DN2→DN3 逐级写入</li>
<li>Ack 确认与完成：DN3→DN2→DN1→Client 逐级返回 Ack，所有副本写完才算成功</li>
</ol>
<h4 id="核心要点">核心要点</h4>
<ul>
<li>控制流 vs 数据流：先问 NN 拿地址 (控制流)，再找 DN 传数据 (数据流)，读写流程的关键在于分离两种流。</li>
<li>空间占用计算公式：HDFS 空间 = 文件大小 × 副本数，Block 大小不影响总空间占用。</li>
</ul>
<hr>
<h2 id="CHAPTER-04-HDFS-高可用与扩展能力">CHAPTER 04 HDFS 高可用与扩展能力</h2>
<h3 id="核心掌握：HDFS-Federation-、-HA-架构及故障切换机制">核心掌握：HDFS Federation 、 HA 架构及故障切换机制</h3>
<h3 id="一、HDFS-Federation-扩展命名空间">一、HDFS Federation: 扩展命名空间</h3>
<h4 id="单-NameNode-的扩展性瓶颈">单 NameNode 的扩展性瓶颈</h4>
<ul>
<li>问题：单 NameNode 内存受限，无法存储海量文件元数据（每个文件 / Block 占用约 150 字节元数据）</li>
<li>影响：限制集群扩展性，无法支持更多文件存储</li>
</ul>
<h4 id="Federation-核心思想">Federation 核心思想</h4>
<ul>
<li>架构特点: <strong>多个 NameNode 独立管理不同的命名空间，互不干扰</strong>；DataNode 共享，物理存储不隔离。</li>
<li>逻辑划分：通过块池 (Block Pool) 划分，每个 NN 管理一个 Block Pool。</li>
</ul>
<blockquote>
<p>✅ 核心辨析：Federation 扩容命名空间，HA 容错命名空间；Federation 不是 HA，两者可以独立部署或组合使用。</p>
</blockquote>
<h3 id="二、HDFS-HA-消除单点故障">二、HDFS HA: 消除单点故障</h3>
<h4 id="HA-解决的问题">HA 解决的问题</h4>
<ul>
<li>问题：单 NameNode 存在单点故障 (SPOF)，一旦宕机，整个 HDFS 集群不可用。</li>
<li>目标：保证服务高可用， RTO (恢复时间目标) 在分钟级。</li>
<li>方案: Active / Standby 双 NameNode 架构，同一命名空间由两个 NN 管理。</li>
</ul>
<h4 id="HA-核心组件与职责">HA 核心组件与职责</h4>
<ol>
<li><strong>Active NameNode</strong>：处理所有客户端请求，对外提供服务</li>
<li><strong>Standby NameNode</strong>：同步 EditLog，定期 Checkpoint，时刻准备接管</li>
<li><strong>QJM</strong>：基于 Paxos 算法管理共享 Edits 存储，防止脑裂</li>
<li><strong>ZKFC</strong>：与 NN 同机部署，监控进程健康，向 ZK 抢占锁</li>
<li><strong>ZooKeeper</strong>：提供分布式锁与选主协调服务</li>
</ol>
<h4 id="QJM-Quorum-Journal-Manager-原理">QJM (Quorum Journal Manager) 原理</h4>
<ul>
<li>基于 Paxos，Active NN 写入，Standby NN 读取；只有多数派 (2N+1) 写入成功才算提交，防止脑裂。</li>
<li>JournalNode 数量必须部署奇数个 (至少 3 个)，遵循多数派原则。</li>
</ul>
<h3 id="三、自动故障切换流程详解">三、自动故障切换流程详解</h3>
<ol>
<li><strong>故障检测</strong>：Active NN 的 ZKFC 检测到进程异常，ZK 会话丢失。</li>
<li><strong>选主竞争</strong>：Standby NN 的 ZKFC 抢占 ZK 临时节点，保证只有一个 ZKFC 能成功。</li>
<li><strong>隔离 (Fencing)</strong>：成功抢锁的 ZKFC 强制杀掉旧 Active 进程，防止双写 / 脑裂。</li>
<li><strong>状态切换</strong>：新 Active 从 QJM 同步 EditLog，提升状态为 Active，客户端自动重试连接。</li>
</ol>
<hr>
<h2 id="CHAPTER-05-MapReduce-编程模型与-Shuffle">CHAPTER 05 MapReduce 编程模型与 Shuffle</h2>
<h3 id="核心掌握：MapReduce-执行阶段、-Shuffle-机制及优化策略">核心掌握：MapReduce 执行阶段、 Shuffle 机制及优化策略</h3>
<h3 id="一、MapReduce-编程模型完整流程">一、MapReduce 编程模型完整流程</h3>
<p><strong>标准执行阶段</strong>: InputSplit → Map → Shuffle → Reduce → Output</p>
<ol>
<li><strong>InputSplit</strong>：数据的逻辑切分，决定 MapTask 并行度；与 Block 区别：Split 是计算视角，Block 是存储视角。</li>
<li><strong>Map</strong>：对每条记录执行 map () 函数，输出中间键值对。</li>
<li><strong>Shuffle</strong>：连接 Map 与 Reduce 的桥梁，数据重分布，<strong>性能瓶颈</strong>。</li>
<li><strong>Reduce</strong>：对相同 key 的 value 列表聚合处理。</li>
<li><strong>Output</strong>：输出最终结果到 HDFS。</li>
</ol>
<h3 id="二、Shuffle-阶段详解">二、Shuffle 阶段详解</h3>
<ol>
<li><strong>分区 (Partition)</strong>：决定数据分发到哪个 Reducer，默认 hash (key) % numReducers。</li>
<li><strong>排序 (Sort)</strong>：按 key 排序，为 Reduce 阶段的有序输入做准备。</li>
<li><strong>溢写 (Spill)</strong>：内存缓冲区满后溢写到磁盘，生成临时文件。</li>
<li><strong>归并 (Merge)</strong>：Map 端合并多个溢写文件，Reduce 端合并来自不同 Map 的输出。</li>
<li><strong>拷贝 (Copy)</strong>：ReduceTask 从 MapTask 所在节点拉取数据。</li>
<li><strong>分组 (Group)</strong>：按 key 分组，相同 key 的 value 列表传递给 reduce () 函数。</li>
</ol>
<h3 id="三、Shuffle-性能瓶颈与优化策略">三、Shuffle 性能瓶颈与优化策略</h3>
<h4 id="核心定位-2">核心定位</h4>
<p>Shuffle 是 MapReduce 的心脏与性能瓶颈 —— 涉及大量网络带宽、磁盘 I/O、序列化、排序开销。</p>
<h4 id="核心优化手段">核心优化手段</h4>
<ol>
<li><strong>Combiner</strong>: Map 端本地预聚合，减少网络传输数据量；适用满足交换律 / 结合律的操作（sum/count/max/min），<strong>可选优化、不能改变业务逻辑</strong>。</li>
<li><strong>Partitioner</strong>: 决定数据分发策略，核心目标是<strong>将相同 key 汇聚到同一 Reducer</strong>，而非单纯的负载均衡；自定义分区可缓解数据倾斜。</li>
</ol>
<h3 id="四、适用场景与高频考点">四、适用场景与高频考点</h3>
<h4 id="适用场景">适用场景</h4>
<p>离线批处理、ETL、日志分析、倒排索引构建。</p>
<h4 id="不适用场景">不适用场景</h4>
<p>低延迟流式计算、迭代计算、内存密集型计算。</p>
<h4 id="易错点">易错点</h4>
<ul>
<li>MapTask 并行度由 InputSplit 个数决定，不是文件大小 / Block 大小。</li>
<li>Shuffle 是最耗时阶段，调优重点在于减少数据量、优化网络传输、减少磁盘 I/O。</li>
</ul>
<hr>
<h2 id="CHAPTER-06-YARN-资源管理与调度">CHAPTER 06 YARN 资源管理与调度</h2>
<h3 id="核心掌握：YARN-架构演进、核心组件与调度策略">核心掌握：YARN 架构演进、核心组件与调度策略</h3>
<h3 id="一、从-MRv1-到-YARN-架构演进与解耦">一、从 MRv1 到 YARN : 架构演进与解耦</h3>
<h4 id="MRv1-的痛点">MRv1 的痛点</h4>
<ul>
<li>JobTracker 单点瓶颈：资源管理 + 任务调度耦合，压力大，扩展性差。</li>
<li>扩展性差：集群规模受限，无法支持上万节点。</li>
<li>不支持非 MR 任务：只能运行 MapReduce 任务。</li>
</ul>
<h4 id="YARN-的核心：解耦">YARN 的核心：解耦</h4>
<ul>
<li>资源管理 (RM) 与任务调度 ( AM ) 解耦，RM 全局管理，AM 应用级管理。</li>
<li>支持多种计算框架：Spark 、 Flink 、 MapReduce 等共享集群资源。</li>
<li>提升扩展性：支持更大规模集群，资源利用率提升。</li>
</ul>
<h3 id="二、YARN-核心组件与职责">二、YARN 核心组件与职责</h3>
<ol>
<li><strong>RM - ResourceManager</strong>：全局资源管理器，资源分配与调度，处理 Client 请求，监控 NM。</li>
<li><strong>NM - NodeManager</strong>：单节点代理，管理容器生命周期，汇报资源使用情况。</li>
<li><strong>AM - ApplicationMaster</strong>：每个应用一个，向 RM 申请资源，与 NM 交互启动 / 停止 Container。</li>
<li><strong>C - Container</strong>：资源抽象单位，<strong>不负责 HDFS 数据存储</strong>。</li>
</ol>
<h3 id="三、YARN-调度器与容错机制">三、YARN 调度器与容错机制</h3>
<h4 id="三大调度器">三大调度器</h4>
<ol>
<li><strong>FIFO 调度器</strong>：先进先出，简单但不支持多租户 / 优先级；适用单用户、小集群测试环境。</li>
<li><strong>Capacity 调度器</strong>：多队列，预留容量，支持多租户；保证各组织最小资源，资源空闲可共享；适用生产环境。</li>
<li><strong>Fair 调度器</strong>：公平共享，动态调整资源分配；资源空闲时可被其他队列借用，弹性好。</li>
</ol>
<h4 id="容错机制">容错机制</h4>
<ul>
<li>Task 失败：AM 会重试 (默认 4 次)，不影响整个应用。</li>
<li>NodeManager 失败：RM 检测心跳超时，将其上 Container 标记失败，由 AM 重新申请资源。</li>
<li>ApplicationMaster 失败：RM 重启 AM。</li>
</ul>
<blockquote>
<p>✅ 核心易错点：RM 负责 “集群级” 资源分配，不负责具体作业内部的任务监控与容错（AM 负责）；Container 是 “计算资源 + 环境” 的封装，不是 HDFS 的 Block。</p>
</blockquote>
<hr>
<h2 id="CHAPTER-07-Spark-核心抽象与执行机制">CHAPTER 07 Spark 核心抽象与执行机制</h2>
<h3 id="核心掌握：Spark-技术栈、-RDD-DataFrame-Dataset-及依赖关系">核心掌握：Spark 技术栈、 RDD/DataFrame/Dataset 及依赖关系</h3>
<h3 id="一、Spark-技术栈">一、Spark 技术栈</h3>
<ol>
<li><strong>Spark Core</strong>：基础引擎，负责任务调度、内存管理、故障恢复、存储系统交互。</li>
<li><strong>Spark SQL</strong>：结构化数据处理，操作 DataFrame/Dataset (非 RDD)，兼容 Hive。</li>
<li><strong>Spark Streaming</strong>：微批处理 (Micro-batch)，高吞吐，秒级延迟。</li>
<li><strong>MLlib &amp; GraphX</strong>：机器学习与图计算库，GraphX 是图计算框架 (不是图数据库)。</li>
</ol>
<h3 id="二、RDD-vs-DataFrame-vs-Dataset">二、RDD vs DataFrame vs Dataset</h3>
<ol>
<li><strong>RDD</strong>：弹性分布式数据集，底层对象，强类型，不可变，Lazy 执行，需手动优化。</li>
<li><strong>DataFrame</strong>：RDD + Schema (类似 Table)，弱类型，Catalyst 优化器可优化执行计划。</li>
<li><strong>Dataset</strong>：DataFrame + Type Safety (强类型)，兼具类型安全与优化。</li>
</ol>
<ul>
<li>转换关系：三者可相互转换 (<code>.rdd</code>, <code>.toDF()</code>, <code>.as[]</code>)；DataSet 在 Scala/Java 中常用，Python 中主要是 DataFrame。</li>
</ul>
<h3 id="三、依赖关系、Stage-划分与容错成本">三、依赖关系、Stage 划分与容错成本</h3>
<h4 id="窄依赖-vs-宽依赖">窄依赖 vs 宽依赖</h4>
<ol>
<li><strong>窄依赖 (Narrow)</strong>：父 RDD 分区只被一个子 RDD 分区使用，可 Pipeline 执行，无 Shuffle；容错成本低，只需重算丢失分区。</li>
<li><strong>宽依赖 (Wide)</strong>：父 RDD 分区被多个子 RDD 分区使用，涉及网络传输，有 Shuffle；容错成本高，可能级联重算所有父分区。</li>
</ol>
<h4 id="Stage-划分原理">Stage 划分原理</h4>
<ul>
<li>划分边界：以宽依赖 (Shuffle) 为边界划分 Stage。</li>
<li>窄依赖处理：窄依赖合并在同一个 Task 中流水线执行。</li>
<li>性能瓶颈: Shuffle 是性能瓶颈，调优重点。</li>
</ul>
<blockquote>
<p>✅ 核心：Spark 基于内存计算 + DAG 优化 + 线程级 Task，比 MapReduce 快 10-100 倍；持久化与缓存可避免重复计算，加速迭代算法。</p>
</blockquote>
<hr>
<h2 id="CHAPTER-08-Hive-数据仓库与表设计">CHAPTER 08 Hive 数据仓库与表设计</h2>
<h3 id="核心掌握：Hive-定位、内外表区别、存储格式与分区分桶">核心掌握：Hive 定位、内外表区别、存储格式与分区分桶</h3>
<h3 id="一、Hive-核心定位与内外表辨析">一、Hive 核心定位与内外表辨析</h3>
<h4 id="核心定位-3">核心定位</h4>
<ul>
<li>定位：基于 HDFS 的数据仓库工具，提供 HiveQL (类 SQL)，将 SQL 转换为 MapReduce / Spark 任务执行。</li>
<li>元数据 (Metadata): 表名、列、分区等信息存放在 Metastore (通常是 MySQL)；实际数据存放在 HDFS。</li>
</ul>
<h4 id="内部表-vs-外部表">内部表 vs 外部表</h4>
<ol>
<li><strong>内部表 (Managed)</strong>
<ul>
<li>Hive 管理元数据和数据，DROP TABLE 时，元数据和 HDFS 数据都被删除。</li>
<li>适用：数据由 Hive 独占、临时表、中间结果表。</li>
</ul>
</li>
<li><strong>外部表 (External)</strong>
<ul>
<li>Hive 只管理元数据，DROP TABLE 时，只删元数据，保留 HDFS 数据。</li>
<li>适用：数据多工具共享、防止误删数据、数据安全性要求高。</li>
</ul>
</li>
</ol>
<h3 id="二、存储格式-TextFile-vs-ORC-vs-Parquet">二、存储格式: TextFile vs ORC vs Parquet</h3>
<ol>
<li><strong>TextFile</strong>：行式存储，文本格式，可读性好；缺点：占用空间大，压缩比低，解析慢，不支持列裁剪；适用小数据量测试、数据交换。</li>
<li><strong>ORC</strong>：列式存储，专为 Hadoop 设计；优点：压缩比高，查询快，支持列裁剪，内置索引；适用 Hive 数仓、OLAP 查询。</li>
<li><strong>Parquet</strong>：列式存储，跨语言、跨平台；优点：压缩比高，支持嵌套数据结构；适用 Spark 、复杂数据结构。</li>
</ol>
<blockquote>
<p>✅ 核心：列式存储适合 OLAP，行式存储适合 OLTP；大数据数仓优先选择 ORC/Parquet，大幅减少 I/O 和存储成本。</p>
</blockquote>
<h3 id="三、分区-Partition-与分桶-Bucketing-设计">三、分区 (Partition) 与分桶 ( Bucketing ) 设计</h3>
<h4 id="分区-Partition">分区 (Partition)</h4>
<ul>
<li>本质: HDFS 上的目录，如 …/date=20251222/ 。</li>
<li>作用：裁剪扫描范围，提升查询效率。</li>
<li>字段选择：低基数、查询过滤高频字段 (如日期、地域)。</li>
</ul>
<h4 id="分桶-Bucketing">分桶 (Bucketing)</h4>
<ul>
<li>本质: HDFS 上的文件，将数据按哈希取模分散到 N 个文件。</li>
<li>作用：优化 Join 、优化抽样、缓解数据倾斜。</li>
<li>字段选择：高基数、离散分布字段 (如 UserID)。</li>
</ul>
<blockquote>
<p>✅ 易错点：分区是 “分目录”，分桶是 “分文件”；表可同时分区和分桶，但不能用同一字段既分区又分桶；分桶写入必须使用 INSERT … SELECT 触发。</p>
</blockquote>
<hr>
<h2 id="CHAPTER-09-HBase-列族存储模型与系统架构">CHAPTER 09 HBase 列族存储模型与系统架构</h2>
<h3 id="核心掌握：HBase-定位、数据模型、-LSM-Tree-及-RowKey-设计">核心掌握：HBase 定位、数据模型、 LSM-Tree 及 RowKey 设计</h3>
<h3 id="一、HBase-核心定位与数据模型">一、HBase 核心定位与数据模型</h3>
<h4 id="核心定位-4">核心定位</h4>
<ul>
<li>定位：基于 Google BigTable 论文实现的分布式列式数据库 (NoSQL)。</li>
<li>适用场景：海量数据 (PB 级)、高吞吐随机读写、稀疏数据存储。</li>
<li>特点：高可靠、高性能、可伸缩、实时读写。</li>
</ul>
<h4 id="数据模型详解">数据模型详解</h4>
<ol>
<li><strong>表 (Table)</strong>：逻辑上由行和列组成，物理上按列族存储。</li>
<li><strong>行键 (RowKey)</strong>：唯一标识一行，按字典序排序，设计核心：<strong>避免热点</strong>。</li>
<li><strong>列族与时间戳</strong>：列族是物理存储的基本单元，权限 / 压缩 / 缓存都在列族级别设置；支持多版本，默认返回最新版本。</li>
<li><strong>列 (Column)</strong>：列族下的具体列，动态扩展，无需预定义。</li>
</ol>
<h3 id="二、HBase-系统架构">二、HBase 系统架构</h3>
<h4 id="核心组件-2">核心组件</h4>
<ol>
<li><strong>HM - HMaster</strong>：管理节点，Region 分配、负载均衡、DDL 操作；<strong>不参与读写路径</strong>。</li>
<li><strong>RS - RegionServer</strong>：工作节点，处理读写请求，管理 Region；核心操作：Split/Compact。</li>
<li><strong>ZK - ZooKeeper</strong>：协调节点，选主、状态监控、元数据入口；存储 hbase:meta 表位置。</li>
<li><strong>HDFS</strong>：底层存储，持久化 HFile 和 WAL。</li>
</ol>
<h4 id="客户端读写流程">客户端读写流程</h4>
<ol>
<li>客户端通过 ZK 找到 hbase:meta 表位置。</li>
<li>从 meta 表获取 RowKey 所在 RegionServer。</li>
<li>直连 RegionServer 读写数据，无需经过 HMaster。</li>
</ol>
<h3 id="三、LSM-Tree-写入流程与-Compaction-机制">三、LSM-Tree: 写入流程与 Compaction 机制</h3>
<h4 id="写流程-WAL-→-MemStore-→-Flush">写流程: WAL → MemStore → Flush</h4>
<ol>
<li>写入 WAL 保证持久性，即使宕机也能恢复。</li>
<li>写入内存 MemStore，按 key 排序，提供快速查询。</li>
<li>MemStore 达到阈值触发 Flush，生成磁盘文件 HFile。</li>
</ol>
<blockquote>
<p>核心优势: LSM-Tree 将随机写转换为顺序写，写性能极高，适合写多读少场景。</p>
</blockquote>
<h4 id="读流程-BlockCache-→-MemStore-→-HFile">读流程: BlockCache → MemStore → HFile</h4>
<ol>
<li>BlockCache (读缓存)：优先查询读缓存。</li>
<li>MemStore (写缓存)：查询尚未刷盘的最新数据。</li>
<li>HFile (磁盘)：使用 BloomFilter 快速判断行 / 列是否存在。</li>
</ol>
<h4 id="Compaction-机制">Compaction 机制</h4>
<ol>
<li><strong>Minor Compaction</strong>：合并少量 HFile，减少文件数；不清理过期数据，开销小，频繁触发。</li>
<li><strong>Major Compaction</strong>：合并所有 HFile 为一个；清理过期 / 删除数据，开销大，手动或低峰期触发。</li>
</ol>
<h3 id="四、RowKey-设计与列族优化">四、RowKey 设计与列族优化</h3>
<h4 id="RowKey-设计三大原则">RowKey 设计三大原则</h4>
<ol>
<li>长度原则：越短越好 (建议 10-100 字节)，过长影响内存和性能。</li>
<li>散列原则：避免热点，使数据均匀分布（反转、加盐、Hash）。</li>
<li>唯一原则：必须唯一，避免数据覆盖。</li>
</ol>
<h4 id="列族数量优化">列族数量优化</h4>
<ul>
<li>建议 1-3 个，过多会导致性能问题：一个列族 Flush 会触发该 Region 下所有列族 Flush，产生大量小文件。</li>
</ul>
<hr>
<h2 id="CHAPTER-10-Kafka-分布式消息队列与分区有序性">CHAPTER 10 Kafka 分布式消息队列与分区有序性</h2>
<h3 id="核心掌握：Kafka-核心概念、消息交付语义与-Consumer-Group-并行度">核心掌握：Kafka 核心概念、消息交付语义与 Consumer Group 并行度</h3>
<h3 id="一、Kafka-核心概念与架构">一、Kafka 核心概念与架构</h3>
<ol>
<li><strong>Broker</strong>：Kafka 节点，集群中的服务器，无状态，可水平扩展。</li>
<li><strong>Topic</strong>：消息的逻辑分类，类似于数据库的表。</li>
<li><strong>Partition</strong>：Topic 的物理分片，并行处理单元，有序、不可变的追加日志。</li>
<li><strong>Offset</strong>：消息在 Partition 中的唯一标识，用于定位消息。</li>
<li><strong>Producer</strong>：消息生产者，决定消息写入哪个 Partition（Hash Key / 轮询）。</li>
<li><strong>Consumer Group</strong>：消费者组，组内消费者共同消费一个 Topic；一个 Partition 在同一时刻只能被组内的一个 Consumer 消费。</li>
</ol>
<blockquote>
<p>并行度公式: Max 并行度 = Partition 数量；Consumer 数量超过 Partition 数量时，多余的 Consumer 会空闲。</p>
</blockquote>
<h3 id="二、消息有序性与-Consumer-Group-并行度">二、消息有序性与 Consumer Group 并行度</h3>
<h4 id="消息有序性">消息有序性</h4>
<ul>
<li><strong>Partition 级别有序</strong>：Kafka 能保证 Partition 内的消息是有序的。</li>
<li><strong>Topic 级别无序</strong>：不同 Partition 之间的消息无序。</li>
</ul>
<blockquote>
<p>业务应用：要求严格顺序则将相关消息发送到同一 Partition，或 Topic 只配置 1 个 Partition（牺牲并行度）。</p>
</blockquote>
<h3 id="三、消息交付语义与高吞吐原因">三、消息交付语义与高吞吐原因</h3>
<h4 id="三大交付语义">三大交付语义</h4>
<ol>
<li><strong>At-most-once 至多一次</strong>：可能丢，不重复；场景：日志收集；实现：自动提交 offset。</li>
<li><strong>At-least-once 至少一次</strong>：不丢，可能重复 (默认)；场景：大多数业务；实现：处理完业务再提交 offset。</li>
<li><strong>Exactly-once 精确一次</strong>：不丢，不重复；场景：金融交易；实现：幂等性 Producer + 事务支持。</li>
</ol>
<h4 id="Kafka-高吞吐的三大原因">Kafka 高吞吐的三大原因</h4>
<ol>
<li><strong>顺序写磁盘</strong>：消息追加到文件末尾，性能接近内存操作。</li>
<li><strong>零拷贝 (Zero-Copy)</strong>：数据直接从磁盘到网卡，减少 CPU 拷贝次数。</li>
<li><strong>页缓存 (PageCache)</strong>：依赖 OS 的页缓存，减少上下文切换，提高缓存命中率。</li>
</ol>
<hr>
<h2 id="CHAPTER-11-数据采集与流处理基础">CHAPTER 11 数据采集与流处理基础</h2>
<h3 id="核心掌握：Flume-架构与-Spark-Streaming-vs-Flink-对比">核心掌握：Flume 架构与 Spark Streaming vs Flink 对比</h3>
<h3 id="一、Flume-分布式日志采集系统">一、Flume : 分布式日志采集系统</h3>
<h4 id="核心定位-5">核心定位</h4>
<ul>
<li>定位：分布式、可靠、高可用的海量日志采集、聚合和传输系统。</li>
<li>特点：支持多种数据源、可靠传输、实时处理。</li>
<li>架构: Agent 是基本单元，包含 <strong>Source → Channel → Sink</strong> 三组件。</li>
</ul>
<h4 id="Agent-三组件模型">Agent 三组件模型</h4>
<ol>
<li><strong>Source (采集)</strong>：接收数据，支持多种数据源 (Avro、Thrift、Exec、Kafka 等)。</li>
<li><strong>Channel (缓冲)</strong>：临时存储数据，保证数据传输可靠性，支持事务；分 Memory Channel（快、丢数据）和 File Channel（可靠、慢）。</li>
<li><strong>Sink (输出)</strong>：将数据发送到目标系统 (HDFS、Kafka、HBase 等)。</li>
</ol>
<h3 id="二、流处理框架对比-Spark-Streaming-vs-Flink">二、流处理框架对比: Spark Streaming vs Flink</h3>
<h4 id="Spark-Streaming">Spark Streaming</h4>
<ul>
<li>模型: <strong>微批处理 (Micro-batch)</strong>，将实时流拆分为小的时间片 (RDD)，按批次处理。</li>
<li>特点：高吞吐，秒级延迟；与 Spark 生态无缝集成；延迟较高，不是真正流处理。</li>
</ul>
<h4 id="Flink">Flink</h4>
<ul>
<li>模型: <strong>原生流处理 (Native Streaming)</strong>，事件驱动，逐条处理数据。</li>
<li>特点：低延迟 (毫秒级)；支持状态管理和事件时间；真正流处理，批处理是流的特例。</li>
</ul>
<h4 id="窗口类型">窗口类型</h4>
<ol>
<li><strong>滚动窗口 (Tumbling)</strong>：固定大小，不重叠。</li>
<li><strong>滑动窗口 (Sliding)</strong>：固定大小，可重叠。</li>
<li><strong>会话窗口 (Session)</strong>：基于活动间隙动态划分。</li>
</ol>
<hr>
<h2 id="CHAPTER-12-数仓、数据集市与数据湖">CHAPTER 12 数仓、数据集市与数据湖</h2>
<h3 id="核心掌握：数据仓库特征、分层架构与数据湖对比">核心掌握：数据仓库特征、分层架构与数据湖对比</h3>
<h3 id="一、数据仓库：定义与分层架构">一、数据仓库：定义与分层架构</h3>
<h4 id="数据仓库四大特征">数据仓库四大特征</h4>
<ol>
<li><strong>面向主题 (Subject-Oriented)</strong>：围绕特定主题组织数据。</li>
<li><strong>集成 (Integrated)</strong>：整合来自多个数据源的数据，统一格式和编码。</li>
<li><strong>相对稳定 (Non-Volatile)</strong>：数据一旦入库很少修改，主要是追加操作。</li>
<li><strong>反映历史变化 (Time-Variant)</strong>：记录历史变化，支持时间维度分析。</li>
</ol>
<h4 id="数仓分层架构">数仓分层架构</h4>
<ol>
<li><strong>ODS (贴源层)</strong>：原始数据层，与源系统保持一致。</li>
<li><strong>DWD (明细层)</strong>：明细数据层，清洗、去重、规范化。</li>
<li><strong>DWS (汇总层)</strong>：汇总数据层，轻度汇总，按主题汇总。</li>
<li><strong>ADS (应用层)</strong>：应用数据层，面向业务，报表、分析。</li>
</ol>
<blockquote>
<p>分层价值：数据解耦、复用、易于维护、性能优化。</p>
</blockquote>
<h3 id="二、数据湖">二、数据湖</h3>
<h4 id="数据湖-Data-Lake-定义">数据湖 (Data Lake) 定义</h4>
<ul>
<li>存储原始数据 (Raw Data) 的集中式存储库，支持结构化、半结构化、非结构化数据。</li>
<li>Schema 策略: <strong>Schema-on-Read (读时模式)</strong>，使用时定义结构，灵活性高，适合数据科学家。</li>
</ul>
<h4 id="数据沼泽-Data-Swamp">数据沼泽 (Data Swamp)</h4>
<ul>
<li>定义：不加治理的数据湖就是数据沼泽，数据难以发现、理解和使用。</li>
<li>避免方式：建立元数据管理、制定数据质量标准、实施生命周期管理、提供数据发现工具。</li>
</ul>
<h3 id="三、ETL-vs-ELT-与整体对比">三、ETL vs ELT 与整体对比</h3>
<h4 id="ETL-vs-ELT">ETL vs ELT</h4>
<ol>
<li><strong>ETL (传统数仓)</strong>：Extract → Transform → Load，先转换再加载，转换在专用 ETL 服务器执行。</li>
<li><strong>ELT (大数据 / 云数仓)</strong>：Extract → Load → Transform，先加载再转换，利用目标库的算力进行转换。</li>
</ol>
<blockquote>
<p>趋势: ELT 更适合大数据场景，利用分布式计算能力，减少数据传输。</p>
</blockquote>
<h4 id="数据仓库-vs-数据湖">数据仓库 vs 数据湖</h4>
<table>
<thead>
<tr>
<th>特性</th>
<th>数据仓库</th>
<th>数据湖</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据类型</td>
<td>结构化数据</td>
<td>结构化、半结构化、非结构化</td>
</tr>
<tr>
<td>Schema</td>
<td>写时模式 (Schema-on-Write)</td>
<td>读时模式 (Schema-on-Read)</td>
</tr>
<tr>
<td>灵活性</td>
<td>低，需预定义模型</td>
<td>高，敏捷探索</td>
</tr>
<tr>
<td>用户群体</td>
<td>业务分析师 (报表)</td>
<td>数据科学家 (挖掘 / ML)</td>
</tr>
<tr>
<td>成本</td>
<td>较高 (需建模清洗)</td>
<td>较低 (原始存储)</td>
</tr>
<tr>
<td>治理</td>
<td>严格 (元数据 / 质量)</td>
<td>需加强 (防数据沼泽)</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="ECOSYSTEM-大数据技术生态全景图">ECOSYSTEM 大数据技术生态全景图</h2>
<h3 id="存储层">存储层</h3>
<p>HDFS（分布式文件存储）、HBase（列式数据库）、Kafka（消息队列）</p>
<h3 id="计算层">计算层</h3>
<p>MapReduce（离线批处理）、Spark（内存计算）、Flink（原生流处理）</p>
<h3 id="协调与服务">协调与服务</h3>
<p>YARN（资源调度）、ZooKeeper（分布式协调）、Hive（数据仓库）</p>
<h3 id="数据采集">数据采集</h3>
<p>Flume（日志采集）、Sqoop（关系库导入导出）、Logstash（ELK 日志收集）</p>
<h3 id="数据流动路径">数据流动路径</h3>
<p>数据采集 (Flume/Sqoop) → 存储 (HDFS/HBase/Kafka ) → 计算 ( MapReduce/Spark/Flink ) → 应用 ( Hive/BI )</p>
<hr>
<h2 id="复习建议与答题技巧">复习建议与答题技巧</h2>
<ol>
<li>系统复习，理解本质：不要死记硬背，理解每个组件的定位、设计思想和适用场景，建立知识体系。</li>
<li>建立框架，分层作答：使用 “定位→核心抽象→典型能力→生态依赖” 等框架组织答案，逻辑清晰。</li>
<li>辨析概念，避免陷阱：注意区分相似概念，识别题干中的干扰项。</li>
<li>思考题要举一反三：通过思考题深入理解知识点，培养工程思维。</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/" class="category-chain-item">研究生课程</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Big-Data/" class="print-no-link">#Big Data</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>大数据理论与实践</div>
      <div>http://example.com/2025/12/26/大数据理论与实践/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jeremy Cheng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年12月26日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/12/27/%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B%EF%BC%9A%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="统计模型：理论与实践">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">统计模型：理论与实践</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/12/26/%E8%AF%AD%E9%9F%B3%E6%83%85%E7%BB%AA%E8%AF%86%E5%88%AB/" title="语音情绪识别">
                        <span class="hidden-mobile">语音情绪识别</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"VuFNqHSWzChINkJFPCBgzzAA-gzGzoHsz","appKey":"CiPa7Le2LyTY1FdufKsHqM1z","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
